away_team <- row %>% html_node("td[data-stat='away_team']") %>% html_text(trim = TRUE)
venue <- row %>% html_node("td[data-stat='venue']") %>% html_text(trim = TRUE)
match_url_full <- if (!grepl("^http", match_link)) {
paste0("https://fbref.com", match_link)
} else {
match_link
}
match_list[[length(match_list) + 1]] <- data.frame(
gameweek = as.character(gameweek),
date = as.character(date),
home_team = as.character(home_team),
away_team = as.character(away_team),
home_goals = home_goals,
away_goals = away_goals,
venue = as.character(venue),
match_url = as.character(match_url_full),
stringsAsFactors = FALSE
)
}, error = function(e) {})
}
if (length(match_list) == 0) {
message("  [ERROR] No matches parsed from fixtures table")
return(NULL)
}
match_data <- bind_rows(match_list)
match_data <- match_data %>% filter(!is.na(match_url))
message(sprintf("[OK] Found %d completed matches", nrow(match_data)))
return(match_data)
}, error = function(e) {
message(sprintf("ERROR: %s", e$message))
return(NULL)
})
}
################################################################################
# DATA EXTRACTION
################################################################################
scrape_match_all_data <- function(match_url, match_info, league, browser, existing_urls) {
polite_delay()
need_player <- !(match_url %in% existing_urls$player)
need_shots <- !(match_url %in% existing_urls$shots)
data_needed <- c(
if (need_player) "Player Stats" else NULL,
if (need_shots) "Shots" else NULL
)
if (length(data_needed) == 0) {
message("    [SKIP] All data exists")
return(list(player_stats = NULL, shots = NULL, success = TRUE))
}
message(sprintf("  Collecting: %s", paste(data_needed, collapse = ", ")))
page <- tryCatch({ fetch_page(match_url, browser) }, error = function(e) NULL)
if (is.null(page)) {
return(list(player_stats = NULL, shots = NULL, success = FALSE))
}
tryCatch({
match_date <- page %>%
html_nodes("div.scorebox_meta div") %>%
html_text() %>%
.[1] %>%
str_trim()
teams <- page %>%
html_nodes("div.scorebox div:nth-child(1) strong a") %>%
html_text() %>%
.[1:2]
if (length(teams) < 2) {
message("    Could not extract team names")
return(list(player_stats = NULL, shots = NULL, success = FALSE))
}
home_team <- teams[1]
away_team <- teams[2]
results <- list(player_stats = NULL, shots = NULL, success = TRUE)
if (need_player) {
results$player_stats <- extract_combined_player_stats(
page, home_team, away_team, match_date, match_url, match_info, league
)
}
if (need_shots) {
results$shots <- extract_shots(page, home_team, away_team, match_date, match_url, match_info, league)
}
counts <- c()
if (!is.null(results$player_stats)) counts <- c(counts, sprintf("Players: %d", nrow(results$player_stats)))
if (!is.null(results$shots)) counts <- c(counts, sprintf("Shots: %d", nrow(results$shots)))
if (length(counts) > 0) message(sprintf("    [OK] %s", paste(counts, collapse = ", ")))
return(results)
}, error = function(e) {
message(sprintf("    [ERROR] Parse error: %s", e$message))
return(list(player_stats = NULL, shots = NULL, success = FALSE))
})
}
extract_combined_player_stats <- function(page, home_team, away_team, match_date, match_url, match_info, league) {
stats_tables <- page %>% html_nodes("table.stats_table")
# Find Summary tables
summary_home <- NULL; summary_away <- NULL
for (tbl in stats_tables) {
table_id <- html_attr(tbl, "id")
if (!is.na(table_id) && grepl("stats_.*_summary", table_id)) {
if (is.null(summary_home)) {
summary_home <- tbl
} else if (is.null(summary_away)) {
summary_away <- tbl
break
}
}
}
# Find Possession tables
poss_home <- NULL; poss_away <- NULL
for (tbl in stats_tables) {
table_id <- html_attr(tbl, "id")
if (!is.na(table_id) && grepl("stats_.*_possession", table_id)) {
if (is.null(poss_home)) {
poss_home <- tbl
} else if (is.null(poss_away)) {
poss_away <- tbl
break
}
}
}
parse_player_table <- function(table, team_name) {
if (is.null(table)) return(NULL)
headers <- table %>%
html_nodes("thead tr:last-child th") %>%
html_attr("data-stat")
headers[is.na(headers)] <- "player"
rows <- table %>% html_nodes("tbody tr:not(.thead)")
data_list <- lapply(rows, function(row) {
cells <- row %>% html_nodes("th, td")
values <- cells %>% html_text(trim = TRUE)
if (length(values) == 0) return(NULL)
player_link <- row %>% html_node("th a") %>% html_attr("href")
n <- min(length(values), length(headers))
values <- values[1:n]
names(values) <- headers[1:n]
df <- as.data.frame(t(values), stringsAsFactors = FALSE)
df$player_href <- player_link
return(df)
})
data_list <- data_list[!sapply(data_list, is.null)]
if (length(data_list) > 0) {
df <- bind_rows(data_list)
df$team <- team_name
return(df)
}
return(NULL)
}
# Parse Summary
summary_home_df <- parse_player_table(summary_home, home_team)
summary_away_df <- parse_player_table(summary_away, away_team)
summary_df <- bind_rows(summary_home_df, summary_away_df)
# Parse Possession
poss_home_df <- parse_player_table(poss_home, home_team)
poss_away_df <- parse_player_table(poss_away, away_team)
poss_df <- bind_rows(poss_home_df, poss_away_df)
# Combine Summary + Possession
if (!is.null(summary_df) && nrow(summary_df) > 0) {
summary_df$join_key <- paste(summary_df$player, summary_df$team, sep = "|||")
if (!is.null(poss_df) && nrow(poss_df) > 0) {
poss_df$join_key <- paste(poss_df$player, poss_df$team, sep = "|||")
summary_cols <- names(summary_df)
poss_only_cols <- setdiff(names(poss_df), summary_cols)
poss_only_cols <- c("join_key", poss_only_cols)
poss_slim <- poss_df %>%
select(any_of(poss_only_cols)) %>%
distinct(join_key, .keep_all = TRUE)
combined_df <- summary_df %>%
left_join(poss_slim, by = "join_key", suffix = c("", "_poss"))
} else {
combined_df <- summary_df
}
combined_df <- combined_df %>% select(-join_key)
combined_df$league <- league
combined_df$season <- SEASON
combined_df$match_date <- match_date
combined_df$home_team <- home_team
combined_df$away_team <- away_team
combined_df$match_url <- match_url
combined_df$gameweek <- match_info$gameweek
combined_df$venue <- match_info$venue
return(combined_df)
}
return(NULL)
}
################################################################################
# EXTRACT SHOTS - WITH COLUMN NAME FIXES
################################################################################
extract_shots <- function(page, home_team, away_team, match_date, match_url, match_info, league) {
shots_table <- page %>% html_node("table#shots_all")
if (is.null(shots_table)) return(NULL)
headers <- shots_table %>%
html_nodes("thead tr:last-child th") %>%
html_attr("data-stat")
headers[is.na(headers)] <- "minute"
rows <- shots_table %>% html_nodes("tbody tr:not(.thead)")
shots_list <- lapply(rows, function(row) {
cells <- row %>% html_nodes("th, td")
values <- cells %>% html_text(trim = TRUE)
if (length(values) == 0) return(NULL)
n <- min(length(values), length(headers))
values <- values[1:n]
names(values) <- headers[1:n]
as.data.frame(t(values), stringsAsFactors = FALSE)
})
shots_list <- shots_list[!sapply(shots_list, is.null)]
if (length(shots_list) == 0) return(NULL)
shots_df <- bind_rows(shots_list)
# =========================================================================
# FIX COLUMN NAMES - FBref uses different names than our schema
# =========================================================================
# FBref: xg_shot -> Our schema: xg
if ("xg_shot" %in% names(shots_df) && !"xg" %in% names(shots_df)) {
shots_df <- shots_df %>% rename(xg = xg_shot)
}
# FBref: psxg_shot -> Our schema: psxg
if ("psxg_shot" %in% names(shots_df) && !"psxg" %in% names(shots_df)) {
shots_df <- shots_df %>% rename(psxg = psxg_shot)
}
# FBref: team -> Our schema: squad
if ("team" %in% names(shots_df) && (!"squad" %in% names(shots_df) || all(is.na(shots_df$squad)))) {
shots_df$squad <- shots_df$team
}
# Add metadata
shots_df$league <- league
shots_df$season <- SEASON
shots_df$match_date <- match_date
shots_df$home_team <- home_team
shots_df$away_team <- away_team
shots_df$match_url <- match_url
shots_df$gameweek <- match_info$gameweek
return(shots_df)
}
################################################################################
# BATCH WRITE
################################################################################
flush_batch_to_sheets <- function(batch_data, league) {
message("\n  === FLUSHING BATCH ===")
if (!is.null(batch_data$player_stats) && nrow(batch_data$player_stats) > 0) {
write_to_google_sheet(
batch_data$player_stats,
SHEETS_CONFIG$player_match_stats$sheet_id,
SHEETS_CONFIG$player_match_stats$sheet_name,
SCHEMA_PLAYER_MATCH_STATS,
"player stats"
)
save_local_backup(batch_data$player_stats, "player_stats", league)
}
if (!is.null(batch_data$shots) && nrow(batch_data$shots) > 0) {
write_to_google_sheet(
batch_data$shots,
SHEETS_CONFIG$shots$sheet_id,
SHEETS_CONFIG$shots$sheet_name,
SCHEMA_SHOTS,
"shots"
)
save_local_backup(batch_data$shots, "shots", league)
}
message("  === BATCH COMPLETE ===\n")
}
################################################################################
# MAIN WORKFLOW
################################################################################
process_league <- function(league, season, browser, url_cache) {
message("\n################################################################################")
message(sprintf("# Processing: %s %s", league, season))
message("################################################################################")
existing_urls <- get_existing_urls_for_league(league, url_cache)
message(sprintf("  Existing - Player: %d, Shots: %d, Goals: %d",
length(existing_urls$player), length(existing_urls$shots),
length(existing_urls$team_goals)))
all_matches <- scrape_league_match_urls(league, season, browser)
if (is.null(all_matches) || nrow(all_matches) == 0) {
message("[ERROR] No matches found")
return(list(matches_processed = 0, matches_failed = 0))
}
# Team Goals (from fixture list)
new_team_goals <- all_matches %>%
filter(!match_url %in% existing_urls$team_goals) %>%
filter(!is.na(home_goals) & !is.na(away_goals))
if (nrow(new_team_goals) > 0) {
team_goals_df <- new_team_goals %>%
mutate(league = league, season = season) %>%
select(league, season, gameweek, date, home_team, away_team,
home_goals, away_goals, venue, match_url)
write_to_google_sheet(
team_goals_df,
SHEETS_CONFIG$team_goals$sheet_id,
SHEETS_CONFIG$team_goals$sheet_name,
SCHEMA_TEAM_GOALS,
"team goals"
)
message(sprintf("[OK] Wrote %d team goal records", nrow(team_goals_df)))
}
# Filter matches needing page visits
new_matches <- all_matches %>%
filter(!match_url %in% existing_urls$complete)
if (nrow(new_matches) == 0) {
message("[OK] All matches up to date!")
return(list(matches_processed = 0, matches_failed = 0,
player_count = 0, shots_count = 0,
team_goals_count = nrow(new_team_goals)))
}
message(sprintf("\n=== MATCHES TO PROCESS: %d ===", nrow(new_matches)))
message(sprintf("Estimated time: ~%.1f minutes", (nrow(new_matches) * RATE_LIMIT_DELAY) / 60))
batch_player <- list()
batch_shots <- list()
total_processed <- 0
total_failed <- 0
total_player <- 0
total_shots <- 0
batch_count <- 0
for (i in 1:nrow(new_matches)) {
match <- new_matches[i, ]
message(sprintf("\n[%d/%d] %s vs %s", i, nrow(new_matches), match$home_team, match$away_team))
data <- scrape_match_all_data(match$match_url, match, league, browser, existing_urls)
if (isTRUE(data$success)) {
if (!is.null(data$player_stats) && nrow(data$player_stats) > 0) {
batch_player[[length(batch_player) + 1]] <- data$player_stats
}
if (!is.null(data$shots) && nrow(data$shots) > 0) {
batch_shots[[length(batch_shots) + 1]] <- data$shots
}
total_processed <- total_processed + 1
batch_count <- batch_count + 1
} else {
total_failed <- total_failed + 1
}
# Flush batch
if (batch_count >= BATCH_SIZE || i == nrow(new_matches)) {
batch_data <- list(
player_stats = if (length(batch_player) > 0) bind_rows(batch_player) else data.frame(),
shots = if (length(batch_shots) > 0) bind_rows(batch_shots) else data.frame()
)
if (nrow(batch_data$player_stats) > 0 || nrow(batch_data$shots) > 0) {
flush_batch_to_sheets(batch_data, league)
total_player <- total_player + nrow(batch_data$player_stats)
total_shots <- total_shots + nrow(batch_data$shots)
}
batch_player <- list()
batch_shots <- list()
batch_count <- 0
message(sprintf("  >> Progress: %d/%d matches", i, nrow(new_matches)))
}
}
message(sprintf("\n[OK] %s COMPLETE: %d processed, %d failed", league, total_processed, total_failed))
return(list(
matches_processed = total_processed,
matches_failed = total_failed,
player_count = total_player,
shots_count = total_shots,
team_goals_count = nrow(new_team_goals)
))
}
################################################################################
# PARQUET EXPORT TO GOOGLE DRIVE
################################################################################
upload_parquet_to_drive <- function(data, name, folder_id = DRIVE_FOLDER_ID) {
message(sprintf("  Uploading %s.parquet...", name))
if (any(sapply(data, is.list))) {
data <- data %>%
mutate(across(where(is.list), ~sapply(., function(x) if(length(x) == 0) NA else x[[1]])))
}
temp_file <- tempfile(fileext = ".parquet")
arrow::write_parquet(data, temp_file)
file_size <- file.size(temp_file) / 1024 / 1024
message(sprintf("    Size: %.2f MB (%d rows)", file_size, nrow(data)))
existing <- drive_find(
q = sprintf("'%s' in parents and name = '%s.parquet'", folder_id, name),
n_max = 1
)
if (nrow(existing) > 0) {
result <- drive_update(existing$id, media = temp_file)
message(sprintf("    [OK] Updated existing file"))
} else {
result <- drive_upload(
temp_file,
path = as_id(folder_id),
name = paste0(name, ".parquet"),
overwrite = FALSE
)
drive_share(result$id, role = "reader", type = "anyone")
message(sprintf("    [OK] Created new file (ID: %s)", result$id))
}
unlink(temp_file)
return(result$id)
}
export_to_parquet <- function() {
if (!EXPORT_PARQUET_TO_DRIVE) {
message("\n[SKIP] Parquet export disabled (EXPORT_PARQUET_TO_DRIVE = FALSE)")
return(NULL)
}
message("\n================================================================================")
message("EXPORTING TO PARQUET (Google Drive - for fast Shiny app loading)")
message("================================================================================\n")
message("Authenticating with Google Drive...")
drive_auth()
message("[OK] Google Drive authenticated\n")
file_ids <- list()
tryCatch({
message("Reading Player_Match_Stats from Google Sheets...")
player_data <- read_sheet(
SHEETS_CONFIG$player_match_stats$sheet_id,
sheet = SHEETS_CONFIG$player_match_stats$sheet_name
) %>% as.data.frame()
file_ids$player_match_stats <- upload_parquet_to_drive(player_data, "player_match_stats")
message("\nReading Shot_Data from Google Sheets...")
shot_data <- read_sheet(
SHEETS_CONFIG$shots$sheet_id,
sheet = SHEETS_CONFIG$shots$sheet_name
) %>% as.data.frame()
file_ids$shots <- upload_parquet_to_drive(shot_data, "shots")
message("\nReading Team_Goals from Google Sheets...")
team_goals <- read_sheet(
SHEETS_CONFIG$team_goals$sheet_id,
sheet = SHEETS_CONFIG$team_goals$sheet_name
) %>% as.data.frame()
file_ids$team_goals <- upload_parquet_to_drive(team_goals, "team_goals")
message("\n================================================================================")
message("[OK] PARQUET EXPORT COMPLETE")
message("================================================================================")
message(sprintf("Files at: https://drive.google.com/drive/folders/%s", DRIVE_FOLDER_ID))
message("================================================================================\n")
}, error = function(e) {
message(sprintf("\n[ERROR] Parquet export failed: %s", e$message))
message("Sheets data is still intact - you can retry export later\n")
})
return(file_ids)
}
################################################################################
# MAIN
################################################################################
main <- function() {
message("================================================================================")
message("       FBref COMBINED SCRAPER - UNIFIED PLAYER MATCH STATS")
message("================================================================================")
message(sprintf("Leagues: %s", paste(LEAGUES_TO_SCRAPE, collapse = ", ")))
message(sprintf("Season: %s", SEASON))
message("")
message(">> OUTPUT SHEETS:")
message("    * Player_Match_Stats: Combined Summary + Possession")
message("    * Shot_Data: Individual shots (xg, psxg, squad)")
message("    * Team_Goals: Match scores")
message("")
message(sprintf("[CFG] Settings: Batch %d, Rate limit %ds", BATCH_SIZE, RATE_LIMIT_DELAY))
message("================================================================================")
init_backup_dir()
url_cache <- load_all_existing_urls()
browser <- init_browser()
message("\nAuthenticating with Google Sheets...")
tryCatch({
gs4_auth()
message("[OK] Authenticated")
}, error = function(e) {
close_browser(browser)
stop("Auth failed: ", e$message)
})
all_results <- list()
tryCatch({
for (league in LEAGUES_TO_SCRAPE) {
result <- tryCatch({
process_league(league, SEASON, browser, url_cache)
}, error = function(e) {
message(sprintf("ERROR for %s: %s", league, e$message))
NULL
})
if (!is.null(result)) all_results[[league]] <- result
if (league != LEAGUES_TO_SCRAPE[length(LEAGUES_TO_SCRAPE)]) {
message(sprintf("\n[PAUSE] Pausing %ds...", LEAGUE_DELAY))
Sys.sleep(LEAGUE_DELAY)
}
}
}, finally = {
close_browser(browser)
})
# Summary
message("\n================================================================================")
message("                              SUMMARY")
message("================================================================================")
for (league in names(all_results)) {
r <- all_results[[league]]
message(sprintf("[OK] %s: %d matches, %d players, %d shots, %d goals",
league, r$matches_processed, r$player_count, r$shots_count, r$team_goals_count))
}
message("")
message("Sheets:")
message(sprintf("  Player Stats: https://docs.google.com/spreadsheets/d/%s/edit",
SHEETS_CONFIG$player_match_stats$sheet_id))
message(sprintf("  Shots: https://docs.google.com/spreadsheets/d/%s/edit",
SHEETS_CONFIG$shots$sheet_id))
message(sprintf("  Team Goals: https://docs.google.com/spreadsheets/d/%s/edit",
SHEETS_CONFIG$team_goals$sheet_id))
message("================================================================================\n")
# Export to Parquet for fast Shiny app loading
export_to_parquet()
return(all_results)
}
################################################################################
# RUN
################################################################################
# To run ONLY the Parquet export (for existing data):
# gs4_auth(); export_to_parquet()
# To run the full scraper + Parquet export:
result <- main()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
shiny::runApp()
# =========================================================================
# POSITION FILTER BUTTONS
# =========================================================================
observeEvent(input$filter_all, { rv$position_filter <- "all" }, ignoreInit = TRUE)
runApp()
